{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b400934c-bd9f-45dc-8a2c-e63687775091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data handling, preprocessing, and deep learning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e295b1cc-c719-4ffb-a4f6-91fa6ca1d9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Preview:\n",
      "   ID                             TITLE     GENRE  \\\n",
      "0   1      Oscar et la dame rose (2009)     drama   \n",
      "1   2                      Cupid (1997)  thriller   \n",
      "2   3  Young, Wild and Wonderful (1980)     adult   \n",
      "3   4             The Secret Sin (1915)     drama   \n",
      "4   5            The Unrecovered (2007)     drama   \n",
      "\n",
      "                                         DESCRIPTION  \n",
      "0  Listening in to a conversation between his doc...  \n",
      "1  A brother and sister with a past incestuous re...  \n",
      "2  As the bus empties the students for their fiel...  \n",
      "3  To help their unemployed father make ends meet...  \n",
      "4  The film's title refers not only to the un-rec...  \n",
      "\n",
      "Test Data Preview:\n",
      "   ID                        TITLE  \\\n",
      "0   1         Edgar's Lunch (1998)   \n",
      "1   2     La guerra de papá (1977)   \n",
      "2   3  Off the Beaten Track (2010)   \n",
      "3   4       Meu Amigo Hindu (2015)   \n",
      "4   5            Er nu zhai (1955)   \n",
      "\n",
      "                                               GENRE  DESCRIPTION  \n",
      "0  L.R. Brane loves his life - his car, his apart...          NaN  \n",
      "1  Spain, March 1964: Quico is a very naughty chi...          NaN  \n",
      "2  One year in the life of Albin and his family o...          NaN  \n",
      "3  His father has died, he hasn't spoken with his...          NaN  \n",
      "4  Before he was known internationally as a marti...          NaN  \n"
     ]
    }
   ],
   "source": [
    "# Column names based on the dataset description\n",
    "column_names = ['ID', 'TITLE', 'GENRE', 'DESCRIPTION']\n",
    "\n",
    "# Load training and test datasets\n",
    "train_data = pd.read_csv('train_data.txt', sep=' ::: ', engine='python', header=None, names=column_names)\n",
    "test_data = pd.read_csv('test_data.txt', sep=' ::: ', engine='python', header=None, names=column_names)\n",
    "\n",
    "# Display the first few rows of data for validation\n",
    "print(\"Training Data Preview:\")\n",
    "print(train_data.head())\n",
    "\n",
    "print(\"\\nTest Data Preview:\")\n",
    "print(test_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d7006aa-39cd-4d20-a536-1367aace8f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Genres: {'action': 0, 'adult': 1, 'adventure': 2, 'animation': 3, 'biography': 4, 'comedy': 5, 'crime': 6, 'documentary': 7, 'drama': 8, 'family': 9, 'fantasy': 10, 'game-show': 11, 'history': 12, 'horror': 13, 'music': 14, 'musical': 15, 'mystery': 16, 'news': 17, 'reality-tv': 18, 'romance': 19, 'sci-fi': 20, 'short': 21, 'sport': 22, 'talk-show': 23, 'thriller': 24, 'war': 25, 'western': 26}\n"
     ]
    }
   ],
   "source": [
    "# Convert descriptions to lowercase for uniformity and normalization\n",
    "train_data['DESCRIPTION'] = train_data['DESCRIPTION'].astype(str).str.lower()\n",
    "test_data['DESCRIPTION'] = test_data['DESCRIPTION'].astype(str).str.lower()\n",
    "\n",
    "# Encode the genre labels into numerical values using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train_data['GENRE'] = label_encoder.fit_transform(train_data['GENRE'])\n",
    "\n",
    "# Print the unique genres and their encoded values\n",
    "print(\"Encoded Genres:\", dict(zip(label_encoder.classes_, range(len(label_encoder.classes_)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14e49e2e-5518-41e7-85d8-75fe5503c481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (54214, 200), Labels shape: (54214,)\n",
      "Test data shape: (54200, 200)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text data to convert sentences into sequences of integers\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train_data['DESCRIPTION'])\n",
    "\n",
    "# Convert descriptions to sequences\n",
    "X_train = tokenizer.texts_to_sequences(train_data['DESCRIPTION'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['DESCRIPTION'])\n",
    "\n",
    "# Pad sequences to ensure uniform input size (max_len = 200)\n",
    "max_len = 200\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n",
    "y_train = train_data['GENRE']\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}, Labels shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61e23c93-3b97-4e3c-a56e-cc101373f55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Model Summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build a Convolutional Neural Network (CNN) model for text classification\n",
    "model_cnn = Sequential()\n",
    "\n",
    "# Embedding Layer: Convert words into dense vectors\n",
    "model_cnn.add(Embedding(input_dim=5000, output_dim=128, input_length=max_len))\n",
    "\n",
    "# Convolutional Layer: Extract key features using a kernel size of 5\n",
    "model_cnn.add(Conv1D(64, 5, activation='relu'))\n",
    "\n",
    "# Global Max Pooling Layer: Reduce dimensionality by taking the max feature value\n",
    "model_cnn.add(GlobalMaxPooling1D())\n",
    "\n",
    "# Fully Connected Layers\n",
    "model_cnn.add(Dense(64, activation='relu'))\n",
    "model_cnn.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# Compile the model using sparse categorical crossentropy for classification\n",
    "model_cnn.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(\"CNN Model Summary:\")\n",
    "model_cnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f7e65de-d621-44a4-a060-960dd787f0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - accuracy: 0.3655 - loss: 2.2833 - val_accuracy: 0.5030 - val_loss: 1.7609\n",
      "Epoch 2/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - accuracy: 0.5436 - loss: 1.6041 - val_accuracy: 0.5445 - val_loss: 1.5950\n",
      "Epoch 3/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - accuracy: 0.6253 - loss: 1.3045 - val_accuracy: 0.5537 - val_loss: 1.5709\n",
      "Epoch 4/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - accuracy: 0.7163 - loss: 0.9995 - val_accuracy: 0.5462 - val_loss: 1.6777\n",
      "Epoch 5/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - accuracy: 0.8032 - loss: 0.7066 - val_accuracy: 0.5308 - val_loss: 1.8901\n",
      "Epoch 6/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - accuracy: 0.8770 - loss: 0.4558 - val_accuracy: 0.5203 - val_loss: 2.2518\n",
      "Epoch 7/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - accuracy: 0.9323 - loss: 0.2698 - val_accuracy: 0.5036 - val_loss: 2.6654\n",
      "Epoch 8/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.9665 - loss: 0.1552 - val_accuracy: 0.4881 - val_loss: 3.0642\n",
      "Epoch 9/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.9850 - loss: 0.0874 - val_accuracy: 0.4992 - val_loss: 3.4221\n",
      "Epoch 10/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - accuracy: 0.9929 - loss: 0.0559 - val_accuracy: 0.4914 - val_loss: 3.7170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Train the CNN model with training data using validation split\n",
    "history = model_cnn.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Save the trained model for later use\n",
    "model_cnn.save('genre_classification_cnn.h5')\n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f39f82-aacc-4bb0-a391-c76f39c1e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model performance on training data\n",
    "train_loss, train_accuracy = model_cnn.evaluate(X_train, y_train)\n",
    "print(f\"CNN Model Training Accuracy: {train_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
